{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공 신경망 (Artificial Neural Network, ANN)\n",
    "\n",
    "인공 신경망(ANN)은 인간의 뇌의 동작 원리를 모방하여 구현한 기계 학습 모델입니다. 인공 신경망은 입력층, 은닉층, 출력층으로 구성되어 있으며, 각 층은 여러 개의 뉴런으로 이루어져 있습니다. 입력층은 외부로부터 데이터를 받아들이고, 은닉층은 입력층의 데이터를 처리하며, 출력층은 최종 결과를 출력합니다. 각 뉴런은 입력값을 받아 가중치와 활성화 함수를 통해 출력값을 계산합니다. 이러한 계산과정을 통해 ANN은 복잡한 비선형 관계를 모델링하고 예측을 수행할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[텐서플로우 설치]__\n",
    "- 텐서플로우가 설치되지 않았다면 아래 명령어를 실행하여 설치해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org -U tensorflow\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 임포트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **numpy** (`import numpy as np`):\n",
    "  - *목적*: 수치 계산을 위한 라이브러리입니다.\n",
    "  - *기능*: 다차원 배열을 처리하고, 고성능 수학 함수를 제공하며, 행렬 연산과 브로드캐스팅 기능을 지원합니다.\n",
    "\n",
    "- **tensorflow** (`import tensorflow as tf`):\n",
    "  - *목적*: 오픈 소스 기계 학습 프레임워크인 TensorFlow를 사용하기 위한 라이브러리입니다.\n",
    "  \n",
    "- **tensorflow.keras.models.Sequential**:\n",
    "  - *목적*: 순차적인 모델을 생성하기 위한 클래스입니다.\n",
    "  - *설명*: 모델은 레이어를 선형으로 쌓아 구성할 수 있는 순차적인 방식으로 생성됩니다.\n",
    "\n",
    "- **tensorflow.keras.layers.Flatten**:\n",
    "  - *목적*: 입력 데이터를 1차원으로 평탄화시키는 레이어입니다.\n",
    "  - *설명*: 다차원 배열의 데이터를 1차원으로 변환하여 신경망의 입력으로 사용할 수 있습니다.\n",
    "\n",
    "- **tensorflow.keras.layers.Dense**:\n",
    "  - *목적*: 완전 연결(fully connected) 레이어입니다.\n",
    "  - *설명*: 입력과 출력을 모두 연결하여 가중치를 학습합니다. 활성화 함수를 적용할 수 있으며, 다양한 신경망 구조를 만들 수 있습니다.\n",
    "\n",
    "- **sklearn.preprocessing.MinMaxScaler**:\n",
    "  - *목적*: 데이터를 정규화하기 위한 클래스입니다.\n",
    "  - *설명*: 입력 데이터를 특정 범위로 스케일링하여 모델의 학습을 돕는 데 사용됩니다.\n",
    "\n",
    "- **sklearn.model_selection.train_test_split**:\n",
    "  - *목적*: 데이터셋을 훈련 및 테스트 세트로 나누기 위한 함수입니다.\n",
    "  - *설명*: 훈련 데이터로 모델을 학습시키고, 테스트 데이터로 모델의 일반화 성능을 평가하는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터셋 생성\n",
    "##### X는 2개의 무작위 수로 이루어진 100개의 데이터 포인트로 구성\n",
    "##### Y는 X1과 X2를 더한 값이 1보다 큰 경우에는 1, 그렇지 않으면 0으로 레이블링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100, 2)\n",
    "y = np.array([1 if x1 + x2 > 1 else 0 for x1, x2 in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리\n",
    "##### MinMaxScaler를 사용하여 입력 데이터 X를 0과 1 사이의 범위로 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. 훈련 및 테스트 데이터 분할\n",
    "##### 전체 데이터셋을 80%의 훈련 데이터와 20%의 테스트 데이터로 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train_test_split(X_scaled, y, test_size=0.2, random_state=42)`:\n",
    "  - **목적**: 데이터셋을 훈련 세트와 테스트 세트로 나누기 위한 함수입니다.\n",
    "  - **설명**: `train_test_split` 함수는 주어진 데이터셋을 훈련 데이터와 테스트 데이터로 나누어줍니다. 이를 통해 모델을 훈련할 때 사용되는 데이터와 모델의 일반화 성능을 평가할 때 사용되는 데이터를 분리할 수 있습니다. \n",
    "  - **매개변수**:\n",
    "    - `X_scaled`: 입력 데이터로 사용될 특성(Feature) 데이터를 나타냅니다. 주로 2차원 배열 형태로 제공됩니다.\n",
    "    - `y`: 출력 데이터로 사용될 레이블(Label) 데이터를 나타냅니다. 주로 1차원 배열 형태로 제공됩니다.\n",
    "    - `test_size`: 테스트 데이터셋의 비율을 나타내는 값입니다. 주로 0.2와 같은 실수 형태로 지정하며, 전체 데이터셋 중 얼마나 테스트에 사용할지 결정합니다.\n",
    "    - `random_state`: 데이터를 나눌 때 사용되는 난수 생성기의 시드 값입니다. 이 값을 지정하여 동일한 데이터셋을 나눌 때 항상 동일한 결과를 얻을 수 있습니다.\n",
    "  - **반환값**: `train_test_split` 함수는 훈련 데이터와 테스트 데이터를 나누어 반환합니다. 일반적으로 반환값은 다음과 같이 사용됩니다:\n",
    "    - `X_train`: 훈련 데이터의 입력 특성 데이터입니다.\n",
    "    - `X_test`: 테스트 데이터의 입력 특성 데이터입니다.\n",
    "    - `y_train`: 훈련 데이터의 출력 레이블 데이터입니다.\n",
    "    - `y_test`: 테스트 데이터의 출력 레이블 데이터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 인공 신경망 모델 구축\n",
    "##### Sequential 모델을 사용하여 간단한 신경망을 구성합니다.\n",
    "##### 입력층과 은닉층은 16개의 뉴런으로 이루어져 있고, 활성화 함수는 ReLU를 사용합니다.\n",
    "##### 출력층은 1개의 뉴런으로 이루어져 있고, 활성화 함수는 sigmoid를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `activation='relu'`:\n",
    "  - **목적**: 레이어의 활성화 함수로 ReLU(Rectified Linear Unit)를 설정합니다.\n",
    "  - **설명**: ReLU는 인공 신경망에서 가장 일반적으로 사용되는 활성화 함수 중 하나입니다. ReLU 함수는 입력값이 0보다 작을 경우 0으로 출력하고, 0보다 큰 경우에는 입력값을 그대로 출력합니다. 이 함수는 비선형성을 추가하고, 신경망이 복잡한 패턴을 학습할 수 있도록 도와줍니다. ReLU는 계산이 간단하고 그레디언트 소실 문제를 완화하는 장점이 있어 널리 사용됩니다.\n",
    "\n",
    "- `activation='sigmoid'`:\n",
    "  - **목적**: 이진 분류 문제에서 출력 레이어의 활성화 함수로 시그모이드 함수를 설정합니다.\n",
    "  - **설명**: 시그모이드 함수는 0과 1 사이의 값을 출력하는 S자 형태의 함수입니다. 이 함수는 이진 분류 모델에서 주로 사용되며, 출력값을 확률로 해석할 수 있습니다. 시그모이드 함수는 입력값이 양수일 경우 1에 가까운 값을, 음수일 경우 0에 가까운 값을 출력하여 예측 결과를 확률적으로 표현할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 컴파일\n",
    "##### Adam 옵티마이저와 binary_crossentropy 손실 함수를 사용합니다.\n",
    "##### 정확도를 평가 지표로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `optimizer='adam'`:\n",
    "  - *목적*: 모델의 최적화 알고리즘을 설정합니다.\n",
    "  - *설명*: Adam(Optimization Algorithm with Adaptive Moment Estimation)은 경사 하강법의 한 종류로, 학습률을 자동으로 조정하면서 모델 파라미터를 업데이트합니다.\n",
    "\n",
    "- `loss='binary_crossentropy'`:\n",
    "  - *목적*: 손실 함수(loss function)를 설정합니다.\n",
    "  - *설명*: binary_crossentropy는 이진 분류(binary classification) 모델에서 주로 사용되는 손실 함수입니다. 이 함수는 실제 클래스와 예측 클래스 간의 크로스 엔트로피 손실을 계산하여 모델이 예측을 개선하도록 돕니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 훈련\n",
    "##### X_train과 y_train 데이터를 사용하여 모델을 50번의 에포크 동안 훈련합니다.\n",
    "##### 배치 크기는 8로 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `X_train`:\n",
    "  - **목적**: 훈련 데이터의 입력값을 나타냅니다.\n",
    "  - **설명**: `X_train`은 모델을 훈련할 때 사용되는 입력 데이터입니다. 이는 모델이 학습하는 동안 입력으로 사용되는 특성(feature) 값을 담고 있는 배열 또는 행렬입니다.\n",
    "- `y_train`:\n",
    "  - **목적**: 훈련 데이터의 실제 출력값을 나타냅니다.\n",
    "  - **설명**: `y_train`은 모델을 훈련할 때 사용되는 실제 출력 데이터입니다. 이는 입력 데이터인 `X_train`에 대응하는 예측할 출력 값을 담고 있는 배열 또는 벡터입니다.\n",
    "- `epochs=50`:\n",
    "  - **목적**: 전체 데이터셋을 반복하여 모델을 훈련하는 에포크(epoch)의 수를 설정합니다.\n",
    "  - **설명**: `epochs`는 모델이 전체 훈련 데이터를 몇 번 반복하여 학습할지를 결정하는 매개변수입니다. 각 에포크에서 모델은 입력 데이터와 실제 출력 데이터를 사용하여 가중치를 업데이트하고 오차를 최소화합니다. 에포크 수는 모델의 학습 시간과 성능에 영향을 줄 수 있습니다.\n",
    "- `batch_size=8`:\n",
    "  - **목적**: 한 번에 처리되는 샘플의 개수인 배치 크기(batch size)를 설정합니다.\n",
    "  - **설명**: `batch_size`는 모델이 한 번에 처리하는 샘플의 개수를 결정하는 매개변수입니다. 모델은 전체 데이터셋을 작은 배치로 나누어 각 배치에서 가중치를 업데이트합니다. 작은 배치를 사용하면 메모리 사용량을 줄이고 학습 속도를 높일 수 있습니다. 배치 크기는 하드웨어의 제약 사항과 데이터의 특성에 따라 조정할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 모델 평가\n",
    "##### 테스트 데이터(X_test, y_test)를 사용하여 모델의 손실과 정확도를 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.evaluate(X_test, y_test)`:\n",
    "  - **목적**: 모델의 성능을 평가하기 위한 메서드입니다.\n",
    "  - **설명**: `evaluate` 메서드는 모델이 주어진 테스트 데이터셋을 기반으로 예측 결과와 실제 값 사이의 오차를 계산하여 모델의 성능을 평가합니다. 이 메서드는 테스트 데이터셋에 대한 예측 정확도(accuracy)나 손실(loss) 값을 반환합니다. 평가 결과를 통해 모델이 얼마나 잘 일반화되었는지 확인할 수 있습니다. \n",
    "  - **매개변수**:\n",
    "    - `X_test`: 평가에 사용될 테스트 데이터의 입력값을 나타냅니다.\n",
    "    - `y_test`: 평가에 사용될 테스트 데이터의 실제 출력값을 나타냅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 예측 수행\n",
    "##### 새로운 샘플 데이터를 사용하여 예측 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.predict(new_sample_scaled)[0][0]`:\n",
    "  - **목적**: 모델을 사용하여 새로운 샘플의 예측 값을 추론하기 위한 메서드입니다.\n",
    "  - **설명**: `predict` 메서드는 모델을 사용하여 주어진 입력 데이터에 대한 예측 값을 반환합니다. 이 메서드를 사용하면 모델이 훈련된 후에 새로운 입력 데이터에 대한 예측을 수행할 수 있습니다. 예측 값은 모델의 출력 레이어의 활성화 값으로 표현됩니다. `predict` 메서드의 결과로 반환되는 값은 예측 결과의 다차원 배열이므로, 필요한 위치에서 예측 값을 가져와 사용할 수 있습니다.\n",
    "  - **매개변수**:\n",
    "    - `new_sample_scaled`: 예측할 새로운 입력 샘플의 정규화된 데이터를 나타냅니다.\n",
    "  - **출력값**: `predict` 메서드의 결과로 반환되는 값은 예측 결과를 나타내는 다차원 배열입니다. `[0][0]` 인덱스를 사용하여 첫 번째 예측 값을 추출할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 샘플 데이터 예측\n",
    "new_sample = np.array([[0.5, 0.7]])  # 예측할 샘플 데이터\n",
    "new_sample_scaled = scaler.transform(new_sample)  # 데이터 전처리\n",
    "\n",
    "# 예측 수행\n",
    "prediction = model.predict(new_sample_scaled)[0][0]\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(\"New Sample Prediction:\")\n",
    "print(f\"Prediction: {prediction:.4f}\")\n",
    "if prediction >= 0.5:\n",
    "    print(\"Class: 1\")\n",
    "else:\n",
    "    print(\"Class: 0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 완료: 인공 신경망 (Artificial Neural Network, ANN) Summary\n",
    "\n",
    "1. 이번 실습에서는 인공 신경망(ANN) 모델을 사용하여 데이터를 학습하고 예측하는 과정을 진행했습니다. ANN은 입력층, 은닉층, 출력층으로 구성된 신경망 구조로, 복잡한 비선형 관계를 모델링할 수 있는 강력한 도구입니다.\n",
    "\n",
    "2. 실습에서는 데이터 전처리, 모델 구축, 모델 컴파일, 훈련, 평가 등의 과정을 진행했습니다. 훈련된 모델은 주어진 데이터에 대해 어떻게 예측을 수행하는지 확인할 수 있었습니다.\n",
    "\n",
    "3. 이 실습을 통해 ANN의 기본 개념과 구현 방법을 익힐 수 있었습니다. ANN은 다양한 응용 분야에서 활용되며, 복잡한 문제를 해결하는 데에 큰 도움을 줄 수 있습니다.\n",
    "\n",
    "4. 더 많은 실습과 응용을 통해 신경망 모델을 더욱 깊게 이해하고, 다양한 데이터에 대해 효과적으로 적용해 보시기 바랍니다. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
